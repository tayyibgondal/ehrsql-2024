{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<!-- Original Implementation by Gyubok Lee -->\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<!-- Refined by Gyubok Lee on 2024-01-15. -->\n",
        "<!-- Note: This Jupyter notebook is tailored to the unique requirements of the EHRSQL project. It includes specific modifications and additional adjustments to cater to the dataset and experiment objectives. -->\n",
        "\n",
        "# Dummy Model Sample Code for EHRSQL: Reliable Text-to-SQL Modeling on Electronic Health Records\n",
        "\n",
        "<p align=\"left\" float=\"left\">\n",
        "  <img src=\"https://github.com/glee4810/ehrsql-2024/raw/master/image/logo.png\" height=\"100\" />\n",
        "</p>\n",
        "\n",
        "<!-- ## Task Introduction\n",
        "The goal of the task is to **develop a reliable text-to-SQL system on EHR**. Unlike standard text-to-SQL tasks, this system must handle all types of questions, including answerable and unanswerable ones with respect to the EHR database structure. For answerable questions, the system must accurately generate SQL queries. For unanswerable questions, the system must correctly identify them as such, thereby preventing incorrect SQL predictions for infeasible questions. The range of questions includes answerable queries about MIMIC-IV, covering topics such as patient demographics, vital signs, and specific disease survival rates ([EHRSQL](https://github.com/glee4810/EHRSQL)). Additionally, there are specially designed unanswerable questions intended to challenge the system. Successfully completing this task will result in the creation of a reliable question-answering system for EHRs, significantly improving the flexibility and efficiency of clinical knowledge exploration in hospitals. -->\n",
        "\n",
        "## Steps of Baseline Code\n",
        "\n",
        "- [x] Step 1: Clone the GitHub Repository and Install Dependencies\n",
        "- [x] Step 2: Import Global Packages and Define File Paths\n",
        "- [x] Step 3: Load Data and Prepare Datasets\n",
        "- [x] Step 4: Building a Dummy Model\n",
        "- [x] Step 5: Evaluation\n",
        "- [x] Step 6: Submission"
      ],
      "metadata": {
        "id": "fV7pV4ue_8Ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Clone the GitHub Repository and Install Dependencies"
      ],
      "metadata": {
        "id": "76ZXSJhhAqZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before you begin, make sure you're in the correct directory. If you need to reset the repository directory, remove the existing directory by uncommenting and executing the following lines:"
      ],
      "metadata": {
        "id": "S1hbegr4BADN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!rm -rf ehrsql-2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc_VUmzR_83L",
        "outputId": "fa64518a-a525-4f60-caad-5a9c32d149fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, clone the repository and install the required Python packages:"
      ],
      "metadata": {
        "id": "OBpg7kpMBEHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cloning the GitHub repository\n",
        "!git clone -q https://github.com/glee4810/ehrsql-2024.git\n",
        "%cd ehrsql-2024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLOhRzcCBB_d",
        "outputId": "3dad4e78-c9e6-4573-a005-0c2fb71e512f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ehrsql-2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the `%load_ext` magic command to automatically reload modules before executing a new line:"
      ],
      "metadata": {
        "id": "O5D2VbclBcJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "1ocUNohyBHUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Import Global Packages and Define File Paths\n",
        "\n",
        "After setting up the repository and dependencies, the next step is to import packages that will be used globally throughout this notebook and to define the file paths to our datasets."
      ],
      "metadata": {
        "id": "wr2zM1EVBj-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Directory paths for database, results and scoring program\n",
        "DB_ID = 'mimic_iv'\n",
        "BASE_DATA_DIR = 'sample_data'\n",
        "RESULT_DIR = 'sample_result_submission/'\n",
        "SCORE_PROGRAM_DIR = 'scoring_program/'\n",
        "\n",
        "# File paths for the dataset and labels\n",
        "TABLES_PATH = os.path.join('data', DB_ID, 'tables.json')               # JSON containing database schema\n",
        "TRAIN_DATA_PATH = os.path.join(BASE_DATA_DIR, 'train', 'data.json')    # JSON file with natural language questions for training data\n",
        "TRAIN_LABEL_PATH = os.path.join(BASE_DATA_DIR, 'train', 'label.json')  # JSON file with corresponding SQL queries for training data\n",
        "VALID_DATA_PATH = os.path.join(BASE_DATA_DIR, 'valid', 'data.json')    # JSON file for validation data\n",
        "DB_PATH = os.path.join('data', DB_ID, f'{DB_ID}.sqlite')               # Database path"
      ],
      "metadata": {
        "id": "PuvpWuLRBeo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Load Data and Prepare Datasets\n",
        "\n",
        "Now that we have our environment and paths set up, the next step is to load the data and prepare it for our model. This involves preprocessing the MIMIC-IV database, reading the data from JSON files, splitting it into training and validation sets, and then initializing our dataset object."
      ],
      "metadata": {
        "id": "grmmBy9cOwg-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and Preprocess MIMIC-IV Database Demo"
      ],
      "metadata": {
        "id": "D5C5pYMbX9In"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://physionet.org/static/published-projects/mimic-iv-demo/mimic-iv-clinical-database-demo-2.2.zip\n",
        "!unzip mimic-iv-clinical-database-demo-2.2\n",
        "!gunzip -r mimic-iv-clinical-database-demo-2.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGvanXz6M2o6",
        "outputId": "f7550d12-7719-4619-a088-780e6ff0bc29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-29 22:57:08--  https://physionet.org/static/published-projects/mimic-iv-demo/mimic-iv-clinical-database-demo-2.2.zip\n",
            "Resolving physionet.org (physionet.org)... 18.18.42.54\n",
            "Connecting to physionet.org (physionet.org)|18.18.42.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16189661 (15M) [application/zip]\n",
            "Saving to: ‘mimic-iv-clinical-database-demo-2.2.zip’\n",
            "\n",
            "mimic-iv-clinical-d 100%[===================>]  15.44M   728KB/s    in 22s     \n",
            "\n",
            "2024-01-29 22:57:30 (718 KB/s) - ‘mimic-iv-clinical-database-demo-2.2.zip’ saved [16189661/16189661]\n",
            "\n",
            "Archive:  mimic-iv-clinical-database-demo-2.2.zip\n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/LICENSE.txt  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/README.txt  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/SHA256SUMS.txt  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/demo_subject_id.csv  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/admissions.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/d_hcpcs.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/d_icd_diagnoses.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/d_icd_procedures.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/d_labitems.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/diagnoses_icd.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/drgcodes.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/emar.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/emar_detail.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/hcpcsevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/labevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/microbiologyevents.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/omr.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/patients.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/pharmacy.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/poe.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/poe_detail.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/prescriptions.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/procedures_icd.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/hosp/provider.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/services.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/hosp/transfers.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/caregiver.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/chartevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/d_items.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/datetimeevents.csv.gz  \n",
            " extracting: mimic-iv-clinical-database-demo-2.2/icu/icustays.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/ingredientevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/inputevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/outputevents.csv.gz  \n",
            "  inflating: mimic-iv-clinical-database-demo-2.2/icu/procedureevents.csv.gz  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd preprocess\n",
        "!bash preprocess.sh\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC30Kt61NzN2",
        "outputId": "08232fe6-b28f-480e-e385-d4cc67c68398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ehrsql-2024/preprocess\n",
            "timeshift is True\n",
            "start_year: 2100\n",
            "time_span: 0\n",
            "current_time: 2100-12-31 23:59:00\n",
            "Processing patients, admissions, icustays, transfers\n",
            "Cannot take a larger sample than population when 'replace=False\n",
            "Use all available patients instead.\n",
            "num_cur_patient: 4\n",
            "num_non_cur_patient: 90\n",
            "num_patient: 94\n",
            "patients, admissions, icustays, transfers processed (took 0.2169 secs)\n",
            "Processing dictionary tables (d_icd_diagnoses, d_icd_procedures, d_labitems, d_items)\n",
            "d_icd_diagnoses, d_icd_procedures, d_labitems, d_items processed (took 2.1067 secs)\n",
            "Processing diagnoses_icd table\n",
            "diagnoses_icd processed (took 0.139 secs)\n",
            "Processing procedures_icd table\n",
            "procedures_icd processed (took 0.0544 secs)\n",
            "Processing labevents table\n",
            "labevents processed (took 2.0276 secs)\n",
            "Processing prescriptions table\n",
            "prescriptions processed (took 0.6992 secs)\n",
            "Processing COST table\n",
            "cost processed (took 0.4841 secs)\n",
            "Processing chartevents table\n",
            "chartevents processed (took 0.8852 secs)\n",
            "Processing inputevents table\n",
            "inputevents processed (took 0.4754 secs)\n",
            "Processing outputevents table\n",
            "outputevents processed (took 0.43 secs)\n",
            "Processing microbiologyevents table\n",
            "microbiologyevents processed (took 0.1564 secs)\n",
            "0               patients\n",
            "1             admissions\n",
            "2        d_icd_diagnoses\n",
            "3       d_icd_procedures\n",
            "4             d_labitems\n",
            "5                d_items\n",
            "6          diagnoses_icd\n",
            "7         procedures_icd\n",
            "8              labevents\n",
            "9          prescriptions\n",
            "10                  cost\n",
            "11           chartevents\n",
            "12           inputevents\n",
            "13          outputevents\n",
            "14    microbiologyevents\n",
            "15              icustays\n",
            "16             transfers\n",
            "Name: name, dtype: object\n",
            "Done!\n",
            "\n",
            "/content/ehrsql-2024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data from JSON"
      ],
      "metadata": {
        "id": "eX31w8dNX5tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data_io import read_json as read_data\n",
        "\n",
        "train_data = read_data(TRAIN_DATA_PATH)\n",
        "train_label = read_data(TRAIN_LABEL_PATH)\n",
        "\n",
        "valid_data = read_data(VALID_DATA_PATH)"
      ],
      "metadata": {
        "id": "m7rIlLiiOxXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Statistics"
      ],
      "metadata": {
        "id": "HUUETad0PtGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train data:\", (len(train_data['data']), len(train_label)))\n",
        "print(\"Valid data:\", len(valid_data['data']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2x-VlDWPrLZ",
        "outputId": "ecc969a3-58ea-487b-ecc8-5bd7c9e1db7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: (20, 20)\n",
            "Valid data: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Format\n",
        "\n",
        "Before proceeding with the model, it is always a good idea to explore the dataset. This includes checking the keys in the dataset, and viewing the first few entries to understand the structure of the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "_MRV2nY_P1C7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore keys and data structure\n",
        "print(train_data.keys())\n",
        "print(train_data['version'])\n",
        "print(train_data['data'][0])\n",
        "\n",
        "# Explore the label structure\n",
        "print(train_label.keys())\n",
        "print(train_label[list(train_label.keys())[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjG8u-kwP6kB",
        "outputId": "57cecb00-f822-4a0c-e975-bb4974fb69c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['version', 'data'])\n",
            "mimic_iv_demo_1.0_train_sample\n",
            "{'id': '3b9849548e56c59f768d5447', 'question': 'Tell me the minimum respiratory rate in patient 10021118 in the first ICU visit.'}\n",
            "dict_keys(['3b9849548e56c59f768d5447', '3f720ea93f94700efe7fe7ee', 'b0b4926abc6fba2f9b78a017', 'ba575890ff7ebaa1dcaa88c2', '84bfcde2dd95748732f9e8a4', '003865fdb611e9f27fe18281', '904c2c0c49be0f63d95d5358', '4d29021ef5a4f0368bdfa1a1', '6866d0c0c9db304d897bd1b8', 'b53daa3c6e0af875928b6bd7', 'e925cbf7b7c9050c2dd7ae1a', 'd9e3f6df43bf2206232807cd', '09eada5be412b54a7d6e3604', '9ce15859816f9b5e712ab02d', 'fc32af7511179af7d45fdec6', 'cb76dc5d463262b63169e9b8', 'e32546ba93600e3d68b462a5', 'f43b1b3a095d2596461aec78', '09bdf5adbc4a4371b27a0b84', 'd76a237f02e60dd98ef55e08'])\n",
            "SELECT MIN(chartevents.valuenum) FROM chartevents WHERE chartevents.stay_id IN ( SELECT icustays.stay_id FROM icustays WHERE icustays.hadm_id IN ( SELECT admissions.hadm_id FROM admissions WHERE admissions.subject_id = 10021118 ) AND icustays.outtime IS NOT NULL ORDER BY icustays.intime ASC LIMIT 1 ) AND chartevents.itemid IN ( SELECT d_items.itemid FROM d_items WHERE d_items.label = 'respiratory rate' AND d_items.linksto = 'chartevents' )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Building a Dummy Model"
      ],
      "metadata": {
        "id": "uFY6RgyFSVgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def generate(self, input_data):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            input_data: list of python dictionaries containing 'id' and 'input'\n",
        "        Returns:\n",
        "            labels: python dictionary containing sql prediction or 'null' values associated with ids\n",
        "        \"\"\"\n",
        "        labels = {}\n",
        "\n",
        "        for sample in input_data:\n",
        "            labels[sample[\"id\"]] = \"null\"\n",
        "\n",
        "        return labels"
      ],
      "metadata": {
        "id": "oYtBKk5iSXmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myModel = Model()\n",
        "data = valid_data[\"data\"]"
      ],
      "metadata": {
        "id": "1KF30SxDgTOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = []\n",
        "for sample in data:\n",
        "    sample_dict = {}\n",
        "    sample_dict['id'] = sample['id']\n",
        "    sample_dict['input'] = sample['question']\n",
        "    input_data.append(sample_dict)"
      ],
      "metadata": {
        "id": "wpiSMICggWzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate answer(SQL)\n",
        "label_y = myModel.generate(input_data)"
      ],
      "metadata": {
        "id": "i7VkY7y1gaW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is how the predicted labels(SQLs) look like"
      ],
      "metadata": {
        "id": "Tvice6Gsu-hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDiQKx4Wgb8C",
        "outputId": "52a54022-9247-450e-cdf9-c251952e3c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'d084d1f3c277e6827087bb44': 'null',\n",
              " '1039ad255c53fd49a3e45f2f': 'null',\n",
              " 'a35a9346ab483d0db0f202ca': 'null',\n",
              " 'aef8b935473950853a7d8448': 'null',\n",
              " '144cd6f1acfad4416003c26c': 'null',\n",
              " 'e3a4a0a695c07e841e1db5aa': 'null',\n",
              " 'b20d40188481222bfbb9b02f': 'null',\n",
              " '154a51192c40cea8dc4c8273': 'null',\n",
              " 'f5f185ff5f7901dc7c4dd711': 'null',\n",
              " '605dc49bacfb0b462cf31880': 'null',\n",
              " 'e6db613772003ec72d44ebe5': 'null',\n",
              " 'dd62c1497314b1bea83b2d03': 'null',\n",
              " '769ea1c5d6c42c47ac9a1735': 'null',\n",
              " 'e5b7cc8f9163e9b60cd96d94': 'null',\n",
              " '6730aa47b18b0105eb3dd8a2': 'null',\n",
              " '3e937842e2eceef28e27788e': 'null',\n",
              " '9d0210cd4045e7f8e860ce69': 'null',\n",
              " '073f2bf50f7338fb5c3bb42b': 'null',\n",
              " 'ffc47b7e01463f229eb09bce': 'null',\n",
              " 'ee3ef44107690c988c06c3e4': 'null'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data_io import write_json as write_label\n",
        "\n",
        "# Save the filtered predictions to a JSON file\n",
        "os.makedirs(RESULT_DIR, exist_ok=True)\n",
        "SCORING_OUTPUT_DIR = os.path.join(RESULT_DIR, 'prediction.json')\n",
        "write_label(SCORING_OUTPUT_DIR, label_y)\n",
        "\n",
        "# Verify the file creation\n",
        "print(\"Listing files in RESULT_DIR:\")\n",
        "!ls {RESULT_DIR}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUMTiYl4hdt_",
        "outputId": "b0f62fe5-b001-40e0-944d-1a15e8f3b135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Listing files in RESULT_DIR:\n",
            "prediction.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Evaluation\n",
        "\n",
        "To get a sense of how well the dummy prediction performs on the traininig set, use the evaluation code below:"
      ],
      "metadata": {
        "id": "wE43I5lH42wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scoring_program.reliability_score import calculate_score, penalize\n",
        "from scoring_program.postprocessing import post_process_sql\n",
        "\n",
        "data = train_data[\"data\"]\n",
        "\n",
        "input_data = []\n",
        "for sample in data:\n",
        "    sample_dict = {}\n",
        "    sample_dict['id'] = sample['id']\n",
        "    sample_dict['input'] = sample['question']\n",
        "    input_data.append(sample_dict)\n",
        "label_y = myModel.generate(input_data)\n",
        "label = train_label\n",
        "\n",
        "real_dict = {id_: post_process_sql(label[id_]) for id_ in label}\n",
        "pred_dict = {id_: post_process_sql(label_y[id_]) for id_ in label_y}\n",
        "assert set(real_dict) == set(pred_dict), \"IDs do not match\"\n",
        "\n",
        "scores = calculate_score(real_dict, pred_dict, db_path=DB_PATH)\n",
        "accuracy0 = penalize(scores, penalty=0)\n",
        "accuracy5 = penalize(scores, penalty=5)\n",
        "accuracy10 = penalize(scores, penalty=10)\n",
        "accuracyN = penalize(scores, penalty=len(scores))\n",
        "\n",
        "print('Scores:')\n",
        "scores_dict = {\n",
        "    'accuracy0': accuracy0*100,\n",
        "    'accuracy5': accuracy5*100,\n",
        "    'accuracy10': accuracy10*100,\n",
        "    'accuracyN': accuracyN*100\n",
        "}\n",
        "print(scores_dict)"
      ],
      "metadata": {
        "id": "0zS133LQ5G-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac692bb-272e-4497-cb43-3c422810e34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scores:\n",
            "{'accuracy0': 50.0, 'accuracy5': 50.0, 'accuracy10': 50.0, 'accuracyN': 50.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Submission\n",
        "\n",
        "Here, we prepare the submission package for the Codabench competition. We begin by compressing the `prediction.json` file into a zip archive, which is the required format for submission."
      ],
      "metadata": {
        "id": "nJT6jj7WiAkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to the directory containing the prediction file\n",
        "%cd {RESULT_DIR}\n",
        "\n",
        "# Compress the prediction.json file into a ZIP archive\n",
        "!zip predictions.zip prediction.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3A9_Oi0AhfQU",
        "outputId": "0833dd48-f92e-49e4-8897-f810f9034ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ehrsql-2024/sample_result_submission\n",
            "  adding: prediction.json (deflated 54%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Submission File: Ensure that the `predictions.zip` file contains only the `prediction.json` file. This ZIP archive is the required format for submission to Codabench.\n",
        "\n",
        "- Submitting on Codabench: Navigate to the Codabench competition page and go to the **My Submissions** tab. Upload the `predictions.zip` file following the provided instructions. Make sure to adhere to any guidelines or submission requirements detailed on the competition page."
      ],
      "metadata": {
        "id": "a-LDPEnlh8wN"
      }
    }
  ]
}